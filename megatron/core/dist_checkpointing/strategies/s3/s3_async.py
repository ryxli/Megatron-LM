from itertools import chain
import logging
import os
import pathlib
from pathlib_abc import PathBase
import queue
from time import time, sleep
from typing import Callable, List, Optional, Tuple, Union

from torch import multiprocessing as mp
import torch
from torch.distributed.checkpoint.filesystem import DEFAULT_SUFFIX, _StoragePrefix, _write_item
from torch.distributed.checkpoint.planner import SavePlan, SavePlanner, WriteItemType
from torch.distributed.checkpoint.storage import WriteResult

from torch.futures import Future

from megatron.core.dist_checkpointing.strategies.filesystem_async import (
    _disable_gc,
    _get_write_results_queue,
    _process_memory,
    _split_by_size_and_type,
)

from megatron.core.dist_checkpointing.strategies.s3.s3_filesystem import VirtualWriter
from s3torchconnectorclient._mountpoint_s3_client import S3Exception

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

WriteBucket = Tuple[pathlib.Path, os.PathLike, PathBase]  # represents writes to a single file


class S3WriterAsync(VirtualWriter):
    """
    Async-enabled implementation of FileSystemWriter using S3
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if not self.single_file_per_rank:
            raise NotImplementedError("single_file_per_rank flag not supported for S3WriterAsync")

        # Intermediate state between preparation and finalization
        self.write_buckets: Optional[List[WriteBucket]] = None
        self.results_queue: Optional[mp.Queue] = None

    def prepare_write_data(self, plan: SavePlan, planner: SavePlanner) -> None:
        """
        First stage of async saving. Copy data to CPU and plan the local saving.

        Args:
            plan (SavePlan): save plan generated by the PyT Distributed compatible planner
            planner (SavePlanner): save planner used to resolve the bytes and tensor data

        Returns: None, but stores the save plan in `self.write_buckets`
        """
        storage_plan: _StoragePrefix = plan.storage_data
        start = time()
        logger.debug(f"thread_count: {self.thread_count}, time: {start}")
        item_buckets = _split_by_size_and_type(self.thread_count, plan.items)
        logger.debug(f"bucket_prep, time: {time() - start}")

        start = time()
        # move tensors from GPU to CPU before starting async writing
        # We do D2H synchronously for now
        file_count = 0

        def gen_file():
            nonlocal file_count
            file_name = f"{storage_plan.prefix}{file_count}{DEFAULT_SUFFIX}"
            file_count += 1
            return file_name

        # Prepare bytes / tensor data in each bucket, which will be assigned to each writer process
        self.write_buckets = []
        for bucket in item_buckets:
            bytes_data = [(item, planner.resolve_data(item)) for item in bucket if item.type == WriteItemType.BYTE_IO]
            tensor_data = [
                (item, planner.resolve_data(item).detach().to("cpu", non_blocking=True))
                for item in bucket
                if item.type != WriteItemType.BYTE_IO
            ]
            if len(bytes_data) > 0 or len(tensor_data) > 0:
                file_name = gen_file()
                self.write_buckets.append((self.path / file_name, file_name, (bytes_data, tensor_data)))

        # Check if there is anything to write on this rank
        if len(self.write_buckets) > 0:
            assert len(self.write_buckets) <= self.thread_count, (
                len(self.write_buckets),
                self.thread_count,
            )
            self.results_queue = _get_write_results_queue()
        else:
            self.results_queue = None
        end = time()
        logger.debug(f"D2H and push, time: {end - start}")

    def get_save_function_and_args(self) -> Tuple[Optional[Callable], Tuple]:
        """
        Get function that saves the data to storage along with its arguments.
        Allows the external caller to apply the save function synchronously or asynchronously.

        Returns: None (if there is nothing to write on this rank) or a tuple of:
            - the function that saves the data
            - arguments to that function
        """
        if not self.write_buckets:
            return None, ()
        return (self.write_preloaded_data_multiproc, (self.write_buckets, self.results_queue))

    @staticmethod
    @_disable_gc()
    def write_preloaded_data_multiproc(write_buckets: List[WriteBucket], global_results_queue: mp.Queue) -> None:
        """
        Performs saving data to storage with multiple processes.

        Starts predefined number of processes and uses 2 queues to make sure the results
        are complete:
        - local_results_queue - to send the actual results
        - count_queue - small queue to mark worker as completed

        Using just one queue disallowed proper exception handling.

        This method is meant to be run in a forked subprocess.
        Triggering GC during execution leads to CUDA errors
        (cleaning up tensors owned by the parent process).
        To prevent this, we disable the GC explicitly for this function with _disable_gc.

        Args:
            write_buckets (List[WriteBucket]): write plan
            global_results_queue (mp.Queue): mp.Queue to collect Dict[List[WriteResults]] (or an Exception)
                from parallel write processes to the main training process
        Returns: None
        """
        w_start = time()
        write_results_or_exc: Union[dict, Exception] = dict()
        ctx = mp.get_context("fork")
        local_results_queue = ctx.Queue()
        count_queue = ctx.JoinableQueue()
        p_list = []

        for i, write_bucket in enumerate(write_buckets):
            try:
                count_queue.put(i)
                p_list.append(
                    ctx.Process(
                        target=S3WriterAsync.write_preloaded_data,
                        args=(i, write_bucket, local_results_queue, count_queue, False),
                    )
                )
            except Exception as e:
                err_msg = f"An error is caught while a proc {i} is created, error: {e}"
                logger.error(err_msg)
                write_results_or_exc = RuntimeError(err_msg)

        if not isinstance(write_results_or_exc, Exception):
            for p in p_list:
                p.start()

            logger.debug("S3WriterAsync: collecting worker results...")

            # To make sure all nodes are completed
            count_queue.join()
            # At this point, all workers completed, so the queue should have exactly `len(write_buckets)` items
            for proc_idx in range(len(write_buckets)):
                try:
                    local_proc_idx, local_results_or_exc = local_results_queue.get()
                except queue.Empty:
                    write_results_or_exc = RuntimeError(
                        f"Unexpected empty `local_results_queue` (got only {proc_idx}/{len(write_buckets)} items)"
                    )
                    break
                else:
                    if isinstance(local_results_or_exc, Exception):
                        err_msg = f"Local process {local_proc_idx} encountered an error: {local_results_or_exc}"
                        logger.error(err_msg)
                        write_results_or_exc = local_results_or_exc
                        break
                    else:
                        assert isinstance(local_results_or_exc, list), type(local_results_or_exc)
                        write_results_or_exc[local_proc_idx] = local_results_or_exc
                        p_list[local_proc_idx].join()

            logger.debug("S3WriterAsync: collected worker results successfully")

        global_results_queue.put(write_results_or_exc)

        w_end = time()
        logger.debug(f"{w_end}, rank: {torch.distributed.get_rank()}, write(sync,parallel): {w_end - w_start}")

    @staticmethod
    @_disable_gc()
    def write_preloaded_data(
        local_proc_idx: int,
        write_bucket: WriteBucket,
        results_queue: mp.SimpleQueue,
        count_queue: mp.JoinableQueue,
        use_fsync: bool,
    ) -> None:
        """
        Performs actual data saving to storage.

        Args:
            local_proc_idx (int): index of a local process that performs writing
            write_bucket (WriteBucket): data to write to storage
            results_queue (mp.Queue): queue to return the write results to the proxy checkpoint process.
            count_queue (mp.JoinableQueue): queue to marks worker task as completed
            use_fsync (bool): if True, calls os.fsync at the end of saving

        Returns: None, the write result are put into the `queue`
        """
        mem_before = _process_memory()

        # TODO: simple retry logic
        max_attempts = 8
        local_output = None
        for attempt in range(max_attempts):
            local_results = []
            try:
                file_name, storage_key, (bytes_data, tensor_data) = write_bucket
                with file_name.open("wb") as stream:
                    for write_item, data in bytes_data:
                        local_results.append(_write_item(stream, data, write_item, storage_key))
                    for write_item, tensor in tensor_data:
                        assert tensor.is_cpu
                        local_results.append(_write_item(stream, tensor, write_item, storage_key))
                local_output = (local_proc_idx, local_results)
                break
            except S3Exception as e:
                logger.warning(f"retry {attempt} encountered s3 exception: {e}")
                local_output = (local_proc_idx, e)
                sleep(min(0.5 * 2**attempt, 3.0))
            except Exception as e:
                logger.warning(f"retry {attempt} encountered other exception: {e}")
                local_output = (local_proc_idx, e)

        results_queue.put(local_output)
        # Signal this process is done.
        count_queue.get()
        count_queue.task_done()

        mem_after = _process_memory()
        logger.debug(f"{local_proc_idx} consumed: {mem_after - mem_before}, before: {mem_before}, after: {mem_after}")

    def write_data(
        self,
        plan: SavePlan,
        planner: SavePlanner,
    ) -> Future[List[WriteResult]]:
        raise NotImplementedError("write_data not implemented for S3WriterAsync")

    def retrieve_write_results(self) -> List[WriteResult]:
        """
        Turn the latest dict including write results from `self.results_queue` into a single results lists. Includes error check.

        Returns (List[WriteResult]): the list of write results from all local processes performing the save.

        """
        assert self.write_buckets is not None

        if self.results_queue is None:
            write_results_or_exc = {}
        else:
            try:
                write_results_or_exc = self.results_queue.get_nowait()
            except queue.Empty:
                raise RuntimeError(f"results_queue should not be empty")

        if isinstance(write_results_or_exc, Exception):
            import traceback

            traceback.print_exc()

            raise RuntimeError(f"Worker failure: {write_results_or_exc}") from write_results_or_exc
        write_results: dict = write_results_or_exc
        if len(write_results) != len(self.write_buckets):
            raise RuntimeError(
                f"Incomplete worker results (expected {len(self.write_buckets)}, got {len(write_results)}."
                f" This probably indicates a worker failure."
            )
        return list(chain.from_iterable(write_results.values()))
